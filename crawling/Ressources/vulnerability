The file robots.txt is useful to find secured or hidden paths for a website.

Here the file is easily accessible by reaching `http://192.168.1.32/robots.txt`.

We see that the server disallow access for any User-Agent on /whatever or `/.hidden`.

In  `http://192.168.1.32/.hidden` there is a lot of folders, difficult to analyze.

To find the flag in this folders we can download all the README files and with a script browse all the files to identify files without repetitive strings found before.
