# Vulnérabilité

Le fichier `robots.txt` est utile pour trouver des chemins cachés ou sécurisés sur un site web.

Il est toujours situé à la racine donc ici `http://192.168.X.X/robots.txt`, c'est un fichier public.

On repère deux chemins restreints: `/whatever` et `/.hidden`.

Sur  `http://192.168.X.X/.hidden` on retrouve une longue liste de dossiers avec des sous dossiers, difficile à analyser manuellement.

Pour trouver le flag dans ces dossiers on peut télécharger tous les fichiers `README` et après avoir identifier des récurrences, exclure les phrases répétitives pour identifier les potentiels fichiers qui diffèrent.

Le flag ressort ensuite facilement.

# Solution

Tout comme le fichier `robots.txt` on peut protéger l'accès aux fichiers/dossiers sensibles via le `.htaccess`.
